{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoataiza/CS7318/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpoRIKhMtPZ",
        "outputId": "383b9bf0-9a62-410a-9d22-7c6ed08ff4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1qZFN_usNLhs"
      },
      "outputs": [],
      "source": [
        "# !pip3 install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-4zrRFr6MGVT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tpHG2tlQM5Xs"
      },
      "outputs": [],
      "source": [
        "col_names = ['Target','Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigree','Age']\n",
        "df = pd.read_csv(r'/content/drive/MyDrive/Uni of Adelaide/CS7318/Assignment 1/indian_diabetes_scaled.csv',header=None,names=col_names,index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K97hYBcPjfe",
        "outputId": "23363cdf-2995-4515-9c3b-9dc0dab892f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Target', 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
              "       'Insulin', 'BMI', 'DiabetesPedigree', 'Age'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns[1:]:\n",
        "  df[col] = df[col].apply(lambda x: float(x[2:]) if type(x) == str else float('NaN'))"
      ],
      "metadata": {
        "id": "RceMp2Tkz5WR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the values: replace the value of no diabetes to 0 instead of -1.\n",
        "df['Target'] = df['Target'].replace(-1,0)"
      ],
      "metadata": {
        "id": "KsMpFB_P1STz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "anjtGiCvFP-N",
        "outputId": "106af67a-1f94-466a-ebea-1855c8a43588"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Target  Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
              "0       0    -0.294118  0.487437       0.180328      -0.292929 -1.000000   \n",
              "1       1    -0.882353 -0.145729       0.081967      -0.414141 -1.000000   \n",
              "2       0    -0.058824  0.839196       0.049180      -1.000000 -1.000000   \n",
              "3       1    -0.882353 -0.105528       0.081967      -0.535354 -0.777778   \n",
              "4       0    -1.000000  0.376884      -0.344262      -0.292929 -0.602837   \n",
              "\n",
              "        BMI  DiabetesPedigree       Age  \n",
              "0  0.001490         -0.531170 -0.033333  \n",
              "1 -0.207153         -0.766866 -0.666667  \n",
              "2 -0.305514         -0.492741 -0.633333  \n",
              "3 -0.162444         -0.923997 -1.000000  \n",
              "4  0.284650          0.887276 -0.600000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bfb0b1a-c9cf-4260-8495-e9f02f0b900f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigree</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.294118</td>\n",
              "      <td>0.487437</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>-0.292929</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.001490</td>\n",
              "      <td>-0.531170</td>\n",
              "      <td>-0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.145729</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>-0.414141</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.207153</td>\n",
              "      <td>-0.766866</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.058824</td>\n",
              "      <td>0.839196</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.305514</td>\n",
              "      <td>-0.492741</td>\n",
              "      <td>-0.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.105528</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>-0.535354</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>-0.162444</td>\n",
              "      <td>-0.923997</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.376884</td>\n",
              "      <td>-0.344262</td>\n",
              "      <td>-0.292929</td>\n",
              "      <td>-0.602837</td>\n",
              "      <td>0.284650</td>\n",
              "      <td>0.887276</td>\n",
              "      <td>-0.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bfb0b1a-c9cf-4260-8495-e9f02f0b900f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bfb0b1a-c9cf-4260-8495-e9f02f0b900f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bfb0b1a-c9cf-4260-8495-e9f02f0b900f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd1123b5-7592-4040-87a2-dfbfe557f999\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd1123b5-7592-4040-87a2-dfbfe557f999')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd1123b5-7592-4040-87a2-dfbfe557f999 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHAtqfS7FNwJ",
        "outputId": "62118787-e11b-4e74-b4f1-c89a9e19ae74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target                int64\n",
              "Pregnancies         float64\n",
              "Glucose             float64\n",
              "BloodPressure       float64\n",
              "SkinThickness       float64\n",
              "Insulin             float64\n",
              "BMI                 float64\n",
              "DiabetesPedigree    float64\n",
              "Age                 float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p_GKH8WOZ9_",
        "outputId": "5398e08d-f12e-49b7-e27d-945c585c21ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.Target.value_counts()"
      ],
      "metadata": {
        "id": "KoMP5N-JLqmO",
        "outputId": "9ad74a3e-cae3-4877-8ce3-a12a0f108333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "0    268\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(x=df.Target)\n",
        "\n",
        "# Taken from https://stackoverflow.com/questions/49044131/how-to-add-data-labels-to-seaborn-countplot-factorplot\n",
        "abs_values = df.Target.value_counts(ascending=True).values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Sw8gE7W0Ffax",
        "outputId": "c6be3d01-5a41-4135-ddca-c988c5e2ebc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, '268'), Text(0, 0, '500')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on how the data is codified, Target = 1 pertains to having no diabetes, and Target = 0 pertains to having diabetes."
      ],
      "metadata": {
        "id": "_HbByGVOcMQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for missing Data"
      ],
      "metadata": {
        "id": "x8ZNbtH4FjJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u6C_prBDVyUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc84779e-887b-4508-bcd1-83e5ddcfb5c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target              0\n",
              "Pregnancies         0\n",
              "Glucose             0\n",
              "BloodPressure       0\n",
              "SkinThickness       0\n",
              "Insulin             0\n",
              "BMI                 0\n",
              "DiabetesPedigree    0\n",
              "Age                 9\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DANtcALqV1Yd"
      },
      "source": [
        "We have missing data. 9 instances of the feature Age is missing. Given that, the missing data only comprises 1.17% of our dataset. We will drop the rows with missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNxnkbP1SYKK"
      },
      "source": [
        "# Dropping the rows with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O_68abdZTDZX"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUhtWLSsZ0tg",
        "outputId": "500a40e2-86b8-47fd-8110-d5a4e879390f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(759, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(x=df.Target)\n",
        "\n",
        "# Taken from https://stackoverflow.com/questions/49044131/how-to-add-data-labels-to-seaborn-countplot-factorplot\n",
        "abs_values = df.Target.value_counts(ascending=True).values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "AeMeoZ-xKOk2",
        "outputId": "40862346-73da-4702-a269-fa6cf8186111"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, '263'), Text(0, 0, '496')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of the missing data, 5 belong to class 0 and 4 belong to class 1."
      ],
      "metadata": {
        "id": "m-NyoVtGLKTq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rODvV4-ZDYN"
      },
      "source": [
        "# Splitting Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted to use KFold here since the dataset only has 759 instances. We will do a train-test split with a proportion of of 80-20. Additionally, we will stratify the target for the model to learn about both classes since one is underrepresented."
      ],
      "metadata": {
        "id": "8LsKVgUfe-A2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MY1mwsOAWJYq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RNpvHToPYTZm"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:,1:]\n",
        "y = df.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JR5tAVOEWU9Q"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=0,train_size = 0.80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Linear Classifiers to predict diabetes"
      ],
      "metadata": {
        "id": "8WMQxy_HHl7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "E73kLadSyhVJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(clf,\n",
        "                   X_train,\n",
        "                   y_train,\n",
        "                   X_test,\n",
        "                   y_test):\n",
        "  clf.fit(X_train,y_train)\n",
        "  print('Training data metrics')\n",
        "  print('---------------------')\n",
        "  y_train_pred = clf.predict(X_train)\n",
        "  print('accuracy:', accuracy_score(y_train,y_train_pred))\n",
        "  print('precision:', precision_score(y_train,y_train_pred))\n",
        "  print('recall:', precision_score(y_train,y_train_pred))\n",
        "  print('f1:', f1_score(y_train,y_train_pred))\n",
        "  print()\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  print('Test data metrics')\n",
        "  print('---------------------')\n",
        "  print('accuracy:', accuracy_score(y_test,y_pred))\n",
        "  print('precision:', precision_score(y_test,y_pred))\n",
        "  print('recall:', precision_score(y_test,y_pred))\n",
        "  print('f1:', f1_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "ebSq6T4-ySje"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "oqMPHq1-Htgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Logistic Regression, the scikit-learn library has a function specifically for Logistic Regression using cross-validation"
      ],
      "metadata": {
        "id": "fvGHLK35j8iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "t8MQVIyFeLcj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(LogisticRegression(random_state=0), X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrcrFz4FhSGb",
        "outputId": "1f199dbb-7464-4c22-ee5f-dce91137e738"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data metrics\n",
            "---------------------\n",
            "accuracy: 0.7792421746293245\n",
            "precision: 0.7981859410430839\n",
            "recall: 0.7981859410430839\n",
            "f1: 0.8400954653937949\n",
            "\n",
            "Test data metrics\n",
            "---------------------\n",
            "accuracy: 0.7697368421052632\n",
            "precision: 0.7666666666666667\n",
            "recall: 0.7666666666666667\n",
            "f1: 0.8401826484018264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machines"
      ],
      "metadata": {
        "id": "xtyIzpwOHtYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "WFfe3jM0HtIf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(SVC(random_state=0),X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isZ8vfk1znrD",
        "outputId": "281a19b9-92af-4140-9596-70b57b53cd50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data metrics\n",
            "---------------------\n",
            "accuracy: 0.8056013179571664\n",
            "precision: 0.8093126385809313\n",
            "recall: 0.8093126385809313\n",
            "f1: 0.8608490566037738\n",
            "\n",
            "Test data metrics\n",
            "---------------------\n",
            "accuracy: 0.7828947368421053\n",
            "precision: 0.7946428571428571\n",
            "recall: 0.7946428571428571\n",
            "f1: 0.8436018957345972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that SVMs slightly outperform Logistic Regression across all metrics. We can refer to this as our benchmark values to compare our neural networks to."
      ],
      "metadata": {
        "id": "aCP1WKGm0031"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzfl_ii6UckU"
      },
      "source": [
        "# Single Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(8)\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "lLJhxiD7_yMl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qWrG4MikayHG"
      },
      "outputs": [],
      "source": [
        "# Converting dataFrames into tensors\n",
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
        "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
        "\n",
        "X_train_t = torch.from_numpy(X_train)\n",
        "X_test_t = torch.from_numpy(X_test)\n",
        "y_train_t = torch.from_numpy(y_train)\n",
        "y_test_t = torch.from_numpy(y_test)\n",
        "\n",
        "train_data_tensor = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_data_tensor, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@shashankshankar10/introduction-to-neural-networks-build-a-single-layer-perceptron-in-pytorch-c22d9b412ccf\n",
        "class SingleLayerNet(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SingleLayerNet, self).__init__()\n",
        "        self.input_layer = torch.nn.Linear(input_size, 1)\n",
        "\n",
        "    #Define how forward\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.input_layer(x))\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "I3xXnGIgBXhb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = SingleLayerNet(8)"
      ],
      "metadata": {
        "id": "WCoAhfzdCJaR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function (criterion)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "# Create an optimizer (Stochastic Gradient Descent - SGD)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "yWMu5-7OCReM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training loop\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rniaR1DLC-rb",
        "outputId": "3b38cdff-57ac-403c-a4e6-6cb0a8447b71"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Loss: 0.7169412970542908\n",
            "Epoch [2/500], Loss: 0.6571578979492188\n",
            "Epoch [3/500], Loss: 0.7275374531745911\n",
            "Epoch [4/500], Loss: 0.7002629637718201\n",
            "Epoch [5/500], Loss: 0.6458228826522827\n",
            "Epoch [6/500], Loss: 0.6259192228317261\n",
            "Epoch [7/500], Loss: 0.6626232266426086\n",
            "Epoch [8/500], Loss: 0.6809318661689758\n",
            "Epoch [9/500], Loss: 0.7048397064208984\n",
            "Epoch [10/500], Loss: 0.6498586535453796\n",
            "Epoch [11/500], Loss: 0.6573231816291809\n",
            "Epoch [12/500], Loss: 0.6431094408035278\n",
            "Epoch [13/500], Loss: 0.6351858973503113\n",
            "Epoch [14/500], Loss: 0.6907500624656677\n",
            "Epoch [15/500], Loss: 0.6611171960830688\n",
            "Epoch [16/500], Loss: 0.7283551096916199\n",
            "Epoch [17/500], Loss: 0.6886494159698486\n",
            "Epoch [18/500], Loss: 0.6775212287902832\n",
            "Epoch [19/500], Loss: 0.6350677609443665\n",
            "Epoch [20/500], Loss: 0.6537355184555054\n",
            "Epoch [21/500], Loss: 0.6676154732704163\n",
            "Epoch [22/500], Loss: 0.7134689092636108\n",
            "Epoch [23/500], Loss: 0.6830090880393982\n",
            "Epoch [24/500], Loss: 0.6888450384140015\n",
            "Epoch [25/500], Loss: 0.6638306975364685\n",
            "Epoch [26/500], Loss: 0.6523579359054565\n",
            "Epoch [27/500], Loss: 0.7667546272277832\n",
            "Epoch [28/500], Loss: 0.5951418280601501\n",
            "Epoch [29/500], Loss: 0.6321080327033997\n",
            "Epoch [30/500], Loss: 0.6304158568382263\n",
            "Epoch [31/500], Loss: 0.6215466856956482\n",
            "Epoch [32/500], Loss: 0.635162353515625\n",
            "Epoch [33/500], Loss: 0.6468677520751953\n",
            "Epoch [34/500], Loss: 0.6688750982284546\n",
            "Epoch [35/500], Loss: 0.6594206690788269\n",
            "Epoch [36/500], Loss: 0.6261630058288574\n",
            "Epoch [37/500], Loss: 0.5930365324020386\n",
            "Epoch [38/500], Loss: 0.7318174242973328\n",
            "Epoch [39/500], Loss: 0.6847816109657288\n",
            "Epoch [40/500], Loss: 0.6291599273681641\n",
            "Epoch [41/500], Loss: 0.578321099281311\n",
            "Epoch [42/500], Loss: 0.6123884320259094\n",
            "Epoch [43/500], Loss: 0.7404133677482605\n",
            "Epoch [44/500], Loss: 0.6345424056053162\n",
            "Epoch [45/500], Loss: 0.702336847782135\n",
            "Epoch [46/500], Loss: 0.6576045155525208\n",
            "Epoch [47/500], Loss: 0.6831053495407104\n",
            "Epoch [48/500], Loss: 0.580337643623352\n",
            "Epoch [49/500], Loss: 0.6363609433174133\n",
            "Epoch [50/500], Loss: 0.6170675158500671\n",
            "Epoch [51/500], Loss: 0.6951411962509155\n",
            "Epoch [52/500], Loss: 0.6609774231910706\n",
            "Epoch [53/500], Loss: 0.6094033718109131\n",
            "Epoch [54/500], Loss: 0.6228763461112976\n",
            "Epoch [55/500], Loss: 0.5848199725151062\n",
            "Epoch [56/500], Loss: 0.5994938611984253\n",
            "Epoch [57/500], Loss: 0.6250344514846802\n",
            "Epoch [58/500], Loss: 0.596577525138855\n",
            "Epoch [59/500], Loss: 0.6165564060211182\n",
            "Epoch [60/500], Loss: 0.7081052660942078\n",
            "Epoch [61/500], Loss: 0.6264324188232422\n",
            "Epoch [62/500], Loss: 0.6051249504089355\n",
            "Epoch [63/500], Loss: 0.6535372138023376\n",
            "Epoch [64/500], Loss: 0.6382756233215332\n",
            "Epoch [65/500], Loss: 0.6519402265548706\n",
            "Epoch [66/500], Loss: 0.748140275478363\n",
            "Epoch [67/500], Loss: 0.651366651058197\n",
            "Epoch [68/500], Loss: 0.6975765228271484\n",
            "Epoch [69/500], Loss: 0.7110005617141724\n",
            "Epoch [70/500], Loss: 0.5952275395393372\n",
            "Epoch [71/500], Loss: 0.6672951579093933\n",
            "Epoch [72/500], Loss: 0.6618397831916809\n",
            "Epoch [73/500], Loss: 0.5493080019950867\n",
            "Epoch [74/500], Loss: 0.684823751449585\n",
            "Epoch [75/500], Loss: 0.5863404870033264\n",
            "Epoch [76/500], Loss: 0.6894734501838684\n",
            "Epoch [77/500], Loss: 0.6657512187957764\n",
            "Epoch [78/500], Loss: 0.6778860688209534\n",
            "Epoch [79/500], Loss: 0.6310897469520569\n",
            "Epoch [80/500], Loss: 0.729516327381134\n",
            "Epoch [81/500], Loss: 0.6008256077766418\n",
            "Epoch [82/500], Loss: 0.6795379519462585\n",
            "Epoch [83/500], Loss: 0.6676496267318726\n",
            "Epoch [84/500], Loss: 0.5668385624885559\n",
            "Epoch [85/500], Loss: 0.6792978048324585\n",
            "Epoch [86/500], Loss: 0.577854335308075\n",
            "Epoch [87/500], Loss: 0.6417881846427917\n",
            "Epoch [88/500], Loss: 0.5803592801094055\n",
            "Epoch [89/500], Loss: 0.7628431916236877\n",
            "Epoch [90/500], Loss: 0.6255810856819153\n",
            "Epoch [91/500], Loss: 0.6921107172966003\n",
            "Epoch [92/500], Loss: 0.6539989709854126\n",
            "Epoch [93/500], Loss: 0.6749656200408936\n",
            "Epoch [94/500], Loss: 0.6326494812965393\n",
            "Epoch [95/500], Loss: 0.7302152514457703\n",
            "Epoch [96/500], Loss: 0.7251378297805786\n",
            "Epoch [97/500], Loss: 0.6511960625648499\n",
            "Epoch [98/500], Loss: 0.7126681208610535\n",
            "Epoch [99/500], Loss: 0.6306264996528625\n",
            "Epoch [100/500], Loss: 0.663340151309967\n",
            "Epoch [101/500], Loss: 0.6389037370681763\n",
            "Epoch [102/500], Loss: 0.6319555044174194\n",
            "Epoch [103/500], Loss: 0.7134028673171997\n",
            "Epoch [104/500], Loss: 0.5525195002555847\n",
            "Epoch [105/500], Loss: 0.6373839974403381\n",
            "Epoch [106/500], Loss: 0.7277839183807373\n",
            "Epoch [107/500], Loss: 0.5907402038574219\n",
            "Epoch [108/500], Loss: 0.6644152998924255\n",
            "Epoch [109/500], Loss: 0.6876183152198792\n",
            "Epoch [110/500], Loss: 0.7500290870666504\n",
            "Epoch [111/500], Loss: 0.6181384921073914\n",
            "Epoch [112/500], Loss: 0.7091965675354004\n",
            "Epoch [113/500], Loss: 0.6759966611862183\n",
            "Epoch [114/500], Loss: 0.6710742115974426\n",
            "Epoch [115/500], Loss: 0.6120391488075256\n",
            "Epoch [116/500], Loss: 0.4958803653717041\n",
            "Epoch [117/500], Loss: 0.5133309364318848\n",
            "Epoch [118/500], Loss: 0.543836236000061\n",
            "Epoch [119/500], Loss: 0.6442369818687439\n",
            "Epoch [120/500], Loss: 0.6174705028533936\n",
            "Epoch [121/500], Loss: 0.6800381541252136\n",
            "Epoch [122/500], Loss: 0.6164023876190186\n",
            "Epoch [123/500], Loss: 0.6721764206886292\n",
            "Epoch [124/500], Loss: 0.6294333338737488\n",
            "Epoch [125/500], Loss: 0.6029389500617981\n",
            "Epoch [126/500], Loss: 0.5714995861053467\n",
            "Epoch [127/500], Loss: 0.678216278553009\n",
            "Epoch [128/500], Loss: 0.6205158829689026\n",
            "Epoch [129/500], Loss: 0.5705130100250244\n",
            "Epoch [130/500], Loss: 0.6457633972167969\n",
            "Epoch [131/500], Loss: 0.5450902581214905\n",
            "Epoch [132/500], Loss: 0.6760111451148987\n",
            "Epoch [133/500], Loss: 0.617171585559845\n",
            "Epoch [134/500], Loss: 0.6210585236549377\n",
            "Epoch [135/500], Loss: 0.6425380110740662\n",
            "Epoch [136/500], Loss: 0.6817067265510559\n",
            "Epoch [137/500], Loss: 0.615637481212616\n",
            "Epoch [138/500], Loss: 0.6602935791015625\n",
            "Epoch [139/500], Loss: 0.6033618450164795\n",
            "Epoch [140/500], Loss: 0.5998634696006775\n",
            "Epoch [141/500], Loss: 0.7543268799781799\n",
            "Epoch [142/500], Loss: 0.63742995262146\n",
            "Epoch [143/500], Loss: 0.5887021422386169\n",
            "Epoch [144/500], Loss: 0.6871225833892822\n",
            "Epoch [145/500], Loss: 0.6206037998199463\n",
            "Epoch [146/500], Loss: 0.618929922580719\n",
            "Epoch [147/500], Loss: 0.5629033446311951\n",
            "Epoch [148/500], Loss: 0.5480450987815857\n",
            "Epoch [149/500], Loss: 0.665524423122406\n",
            "Epoch [150/500], Loss: 0.6674107313156128\n",
            "Epoch [151/500], Loss: 0.6302698254585266\n",
            "Epoch [152/500], Loss: 0.5968140959739685\n",
            "Epoch [153/500], Loss: 0.6692478060722351\n",
            "Epoch [154/500], Loss: 0.6376837491989136\n",
            "Epoch [155/500], Loss: 0.6271094083786011\n",
            "Epoch [156/500], Loss: 0.6463139653205872\n",
            "Epoch [157/500], Loss: 0.6826798915863037\n",
            "Epoch [158/500], Loss: 0.592625081539154\n",
            "Epoch [159/500], Loss: 0.5296247005462646\n",
            "Epoch [160/500], Loss: 0.6213223934173584\n",
            "Epoch [161/500], Loss: 0.5941078066825867\n",
            "Epoch [162/500], Loss: 0.6796263456344604\n",
            "Epoch [163/500], Loss: 0.6328941583633423\n",
            "Epoch [164/500], Loss: 0.5504939556121826\n",
            "Epoch [165/500], Loss: 0.6758756041526794\n",
            "Epoch [166/500], Loss: 0.6089463829994202\n",
            "Epoch [167/500], Loss: 0.6261205077171326\n",
            "Epoch [168/500], Loss: 0.5229775309562683\n",
            "Epoch [169/500], Loss: 0.67132568359375\n",
            "Epoch [170/500], Loss: 0.6434759497642517\n",
            "Epoch [171/500], Loss: 0.6165696382522583\n",
            "Epoch [172/500], Loss: 0.5874072909355164\n",
            "Epoch [173/500], Loss: 0.6582949757575989\n",
            "Epoch [174/500], Loss: 0.6733208894729614\n",
            "Epoch [175/500], Loss: 0.7399956583976746\n",
            "Epoch [176/500], Loss: 0.69374018907547\n",
            "Epoch [177/500], Loss: 0.5687817335128784\n",
            "Epoch [178/500], Loss: 0.5106786489486694\n",
            "Epoch [179/500], Loss: 0.6440975666046143\n",
            "Epoch [180/500], Loss: 0.5857498645782471\n",
            "Epoch [181/500], Loss: 0.5359331965446472\n",
            "Epoch [182/500], Loss: 0.6370349526405334\n",
            "Epoch [183/500], Loss: 0.5590454936027527\n",
            "Epoch [184/500], Loss: 0.5380567312240601\n",
            "Epoch [185/500], Loss: 0.5498623251914978\n",
            "Epoch [186/500], Loss: 0.6060118675231934\n",
            "Epoch [187/500], Loss: 0.6859644055366516\n",
            "Epoch [188/500], Loss: 0.7078933119773865\n",
            "Epoch [189/500], Loss: 0.5819477438926697\n",
            "Epoch [190/500], Loss: 0.7136277556419373\n",
            "Epoch [191/500], Loss: 0.6538688540458679\n",
            "Epoch [192/500], Loss: 0.6702406406402588\n",
            "Epoch [193/500], Loss: 0.68879634141922\n",
            "Epoch [194/500], Loss: 0.5794854760169983\n",
            "Epoch [195/500], Loss: 0.6650070548057556\n",
            "Epoch [196/500], Loss: 0.6699074506759644\n",
            "Epoch [197/500], Loss: 0.6541998386383057\n",
            "Epoch [198/500], Loss: 0.6071168780326843\n",
            "Epoch [199/500], Loss: 0.6784757375717163\n",
            "Epoch [200/500], Loss: 0.6723875403404236\n",
            "Epoch [201/500], Loss: 0.6372731924057007\n",
            "Epoch [202/500], Loss: 0.5749797224998474\n",
            "Epoch [203/500], Loss: 0.5452908873558044\n",
            "Epoch [204/500], Loss: 0.5239342451095581\n",
            "Epoch [205/500], Loss: 0.5381391644477844\n",
            "Epoch [206/500], Loss: 0.5621260404586792\n",
            "Epoch [207/500], Loss: 0.6218876242637634\n",
            "Epoch [208/500], Loss: 0.6945673823356628\n",
            "Epoch [209/500], Loss: 0.7045707702636719\n",
            "Epoch [210/500], Loss: 0.6645355224609375\n",
            "Epoch [211/500], Loss: 0.6235833168029785\n",
            "Epoch [212/500], Loss: 0.5920606851577759\n",
            "Epoch [213/500], Loss: 0.6856623888015747\n",
            "Epoch [214/500], Loss: 0.8029810190200806\n",
            "Epoch [215/500], Loss: 0.6036930680274963\n",
            "Epoch [216/500], Loss: 0.6662971377372742\n",
            "Epoch [217/500], Loss: 0.5460902452468872\n",
            "Epoch [218/500], Loss: 0.6021733283996582\n",
            "Epoch [219/500], Loss: 0.615756630897522\n",
            "Epoch [220/500], Loss: 0.586808443069458\n",
            "Epoch [221/500], Loss: 0.6359220743179321\n",
            "Epoch [222/500], Loss: 0.5726337432861328\n",
            "Epoch [223/500], Loss: 0.5663599967956543\n",
            "Epoch [224/500], Loss: 0.5968345403671265\n",
            "Epoch [225/500], Loss: 0.5619798302650452\n",
            "Epoch [226/500], Loss: 0.5966382622718811\n",
            "Epoch [227/500], Loss: 0.5482553243637085\n",
            "Epoch [228/500], Loss: 0.6077595949172974\n",
            "Epoch [229/500], Loss: 0.6150572299957275\n",
            "Epoch [230/500], Loss: 0.6737948656082153\n",
            "Epoch [231/500], Loss: 0.6340801119804382\n",
            "Epoch [232/500], Loss: 0.6050726175308228\n",
            "Epoch [233/500], Loss: 0.7044538855552673\n",
            "Epoch [234/500], Loss: 0.5845603346824646\n",
            "Epoch [235/500], Loss: 0.6997268199920654\n",
            "Epoch [236/500], Loss: 0.6314033269882202\n",
            "Epoch [237/500], Loss: 0.6149724125862122\n",
            "Epoch [238/500], Loss: 0.6011005640029907\n",
            "Epoch [239/500], Loss: 0.6205025315284729\n",
            "Epoch [240/500], Loss: 0.6570387482643127\n",
            "Epoch [241/500], Loss: 0.5331599712371826\n",
            "Epoch [242/500], Loss: 0.7162072658538818\n",
            "Epoch [243/500], Loss: 0.6531730890274048\n",
            "Epoch [244/500], Loss: 0.5748091340065002\n",
            "Epoch [245/500], Loss: 0.5773422718048096\n",
            "Epoch [246/500], Loss: 0.642842710018158\n",
            "Epoch [247/500], Loss: 0.6034202575683594\n",
            "Epoch [248/500], Loss: 0.5762673020362854\n",
            "Epoch [249/500], Loss: 0.6874940991401672\n",
            "Epoch [250/500], Loss: 0.49071386456489563\n",
            "Epoch [251/500], Loss: 0.5411146283149719\n",
            "Epoch [252/500], Loss: 0.583229124546051\n",
            "Epoch [253/500], Loss: 0.6194587349891663\n",
            "Epoch [254/500], Loss: 0.5640433430671692\n",
            "Epoch [255/500], Loss: 0.6913971304893494\n",
            "Epoch [256/500], Loss: 0.624190092086792\n",
            "Epoch [257/500], Loss: 0.6296153664588928\n",
            "Epoch [258/500], Loss: 0.5775543451309204\n",
            "Epoch [259/500], Loss: 0.5549241304397583\n",
            "Epoch [260/500], Loss: 0.6159577965736389\n",
            "Epoch [261/500], Loss: 0.6199600100517273\n",
            "Epoch [262/500], Loss: 0.4919053018093109\n",
            "Epoch [263/500], Loss: 0.5903987288475037\n",
            "Epoch [264/500], Loss: 0.58238685131073\n",
            "Epoch [265/500], Loss: 0.6415079832077026\n",
            "Epoch [266/500], Loss: 0.5875199437141418\n",
            "Epoch [267/500], Loss: 0.5935315489768982\n",
            "Epoch [268/500], Loss: 0.5298459529876709\n",
            "Epoch [269/500], Loss: 0.5630514025688171\n",
            "Epoch [270/500], Loss: 0.5848420262336731\n",
            "Epoch [271/500], Loss: 0.6553187370300293\n",
            "Epoch [272/500], Loss: 0.5882079005241394\n",
            "Epoch [273/500], Loss: 0.6390571594238281\n",
            "Epoch [274/500], Loss: 0.6025314927101135\n",
            "Epoch [275/500], Loss: 0.6589961051940918\n",
            "Epoch [276/500], Loss: 0.5930851101875305\n",
            "Epoch [277/500], Loss: 0.5191202759742737\n",
            "Epoch [278/500], Loss: 0.5318546891212463\n",
            "Epoch [279/500], Loss: 0.6417496204376221\n",
            "Epoch [280/500], Loss: 0.5633145570755005\n",
            "Epoch [281/500], Loss: 0.616344153881073\n",
            "Epoch [282/500], Loss: 0.6423754096031189\n",
            "Epoch [283/500], Loss: 0.5181442499160767\n",
            "Epoch [284/500], Loss: 0.6089339256286621\n",
            "Epoch [285/500], Loss: 0.688928484916687\n",
            "Epoch [286/500], Loss: 0.6175445318222046\n",
            "Epoch [287/500], Loss: 0.6436387300491333\n",
            "Epoch [288/500], Loss: 0.6230852007865906\n",
            "Epoch [289/500], Loss: 0.5290096402168274\n",
            "Epoch [290/500], Loss: 0.6017625331878662\n",
            "Epoch [291/500], Loss: 0.6043793559074402\n",
            "Epoch [292/500], Loss: 0.6036435961723328\n",
            "Epoch [293/500], Loss: 0.6230883598327637\n",
            "Epoch [294/500], Loss: 0.6318040490150452\n",
            "Epoch [295/500], Loss: 0.6245993971824646\n",
            "Epoch [296/500], Loss: 0.7097145318984985\n",
            "Epoch [297/500], Loss: 0.5184399485588074\n",
            "Epoch [298/500], Loss: 0.5708284974098206\n",
            "Epoch [299/500], Loss: 0.5485909581184387\n",
            "Epoch [300/500], Loss: 0.5052387714385986\n",
            "Epoch [301/500], Loss: 0.5033174753189087\n",
            "Epoch [302/500], Loss: 0.5510828495025635\n",
            "Epoch [303/500], Loss: 0.6471900939941406\n",
            "Epoch [304/500], Loss: 0.6091246604919434\n",
            "Epoch [305/500], Loss: 0.5846713781356812\n",
            "Epoch [306/500], Loss: 0.6889786124229431\n",
            "Epoch [307/500], Loss: 0.5247125029563904\n",
            "Epoch [308/500], Loss: 0.5790433287620544\n",
            "Epoch [309/500], Loss: 0.5366948246955872\n",
            "Epoch [310/500], Loss: 0.5869544148445129\n",
            "Epoch [311/500], Loss: 0.4912365674972534\n",
            "Epoch [312/500], Loss: 0.5850058794021606\n",
            "Epoch [313/500], Loss: 0.6410678625106812\n",
            "Epoch [314/500], Loss: 0.5361308455467224\n",
            "Epoch [315/500], Loss: 0.5341489315032959\n",
            "Epoch [316/500], Loss: 0.6999953389167786\n",
            "Epoch [317/500], Loss: 0.5915388464927673\n",
            "Epoch [318/500], Loss: 0.6562497615814209\n",
            "Epoch [319/500], Loss: 0.5846925377845764\n",
            "Epoch [320/500], Loss: 0.5998555421829224\n",
            "Epoch [321/500], Loss: 0.6781256794929504\n",
            "Epoch [322/500], Loss: 0.5869394540786743\n",
            "Epoch [323/500], Loss: 0.563640296459198\n",
            "Epoch [324/500], Loss: 0.5943121910095215\n",
            "Epoch [325/500], Loss: 0.535615861415863\n",
            "Epoch [326/500], Loss: 0.560192883014679\n",
            "Epoch [327/500], Loss: 0.5747963190078735\n",
            "Epoch [328/500], Loss: 0.6385141611099243\n",
            "Epoch [329/500], Loss: 0.5899644494056702\n",
            "Epoch [330/500], Loss: 0.6332139372825623\n",
            "Epoch [331/500], Loss: 0.6429069638252258\n",
            "Epoch [332/500], Loss: 0.6661074757575989\n",
            "Epoch [333/500], Loss: 0.5176867842674255\n",
            "Epoch [334/500], Loss: 0.5467009544372559\n",
            "Epoch [335/500], Loss: 0.6566527485847473\n",
            "Epoch [336/500], Loss: 0.640217661857605\n",
            "Epoch [337/500], Loss: 0.5216026306152344\n",
            "Epoch [338/500], Loss: 0.4926416575908661\n",
            "Epoch [339/500], Loss: 0.6195281147956848\n",
            "Epoch [340/500], Loss: 0.5585302114486694\n",
            "Epoch [341/500], Loss: 0.5241310000419617\n",
            "Epoch [342/500], Loss: 0.5416380167007446\n",
            "Epoch [343/500], Loss: 0.7122950553894043\n",
            "Epoch [344/500], Loss: 0.5208971500396729\n",
            "Epoch [345/500], Loss: 0.5857618451118469\n",
            "Epoch [346/500], Loss: 0.600891649723053\n",
            "Epoch [347/500], Loss: 0.7282741665840149\n",
            "Epoch [348/500], Loss: 0.6774978041648865\n",
            "Epoch [349/500], Loss: 0.5165231823921204\n",
            "Epoch [350/500], Loss: 0.6133785843849182\n",
            "Epoch [351/500], Loss: 0.6405612230300903\n",
            "Epoch [352/500], Loss: 0.6553250551223755\n",
            "Epoch [353/500], Loss: 0.6810203194618225\n",
            "Epoch [354/500], Loss: 0.6171180009841919\n",
            "Epoch [355/500], Loss: 0.6129677295684814\n",
            "Epoch [356/500], Loss: 0.5519809722900391\n",
            "Epoch [357/500], Loss: 0.6765826940536499\n",
            "Epoch [358/500], Loss: 0.5635178089141846\n",
            "Epoch [359/500], Loss: 0.6181003451347351\n",
            "Epoch [360/500], Loss: 0.7361795902252197\n",
            "Epoch [361/500], Loss: 0.6693070530891418\n",
            "Epoch [362/500], Loss: 0.7047916650772095\n",
            "Epoch [363/500], Loss: 0.5221579074859619\n",
            "Epoch [364/500], Loss: 0.6376232504844666\n",
            "Epoch [365/500], Loss: 0.7171189188957214\n",
            "Epoch [366/500], Loss: 0.45548155903816223\n",
            "Epoch [367/500], Loss: 0.5474968552589417\n",
            "Epoch [368/500], Loss: 0.49280914664268494\n",
            "Epoch [369/500], Loss: 0.4697496294975281\n",
            "Epoch [370/500], Loss: 0.5842404365539551\n",
            "Epoch [371/500], Loss: 0.4785318672657013\n",
            "Epoch [372/500], Loss: 0.49887165427207947\n",
            "Epoch [373/500], Loss: 0.6451873183250427\n",
            "Epoch [374/500], Loss: 0.5968495011329651\n",
            "Epoch [375/500], Loss: 0.5360157489776611\n",
            "Epoch [376/500], Loss: 0.6089648008346558\n",
            "Epoch [377/500], Loss: 0.6179405450820923\n",
            "Epoch [378/500], Loss: 0.579426109790802\n",
            "Epoch [379/500], Loss: 0.6456944942474365\n",
            "Epoch [380/500], Loss: 0.5431649684906006\n",
            "Epoch [381/500], Loss: 0.6379860043525696\n",
            "Epoch [382/500], Loss: 0.7218641042709351\n",
            "Epoch [383/500], Loss: 0.6658688187599182\n",
            "Epoch [384/500], Loss: 0.600953221321106\n",
            "Epoch [385/500], Loss: 0.6346979737281799\n",
            "Epoch [386/500], Loss: 0.5391297340393066\n",
            "Epoch [387/500], Loss: 0.5838003754615784\n",
            "Epoch [388/500], Loss: 0.5382363200187683\n",
            "Epoch [389/500], Loss: 0.6894549131393433\n",
            "Epoch [390/500], Loss: 0.665696918964386\n",
            "Epoch [391/500], Loss: 0.6108988523483276\n",
            "Epoch [392/500], Loss: 0.6143202185630798\n",
            "Epoch [393/500], Loss: 0.6227591037750244\n",
            "Epoch [394/500], Loss: 0.5300504565238953\n",
            "Epoch [395/500], Loss: 0.5734313130378723\n",
            "Epoch [396/500], Loss: 0.5493296384811401\n",
            "Epoch [397/500], Loss: 0.5022705793380737\n",
            "Epoch [398/500], Loss: 0.6203632354736328\n",
            "Epoch [399/500], Loss: 0.5706555843353271\n",
            "Epoch [400/500], Loss: 0.620879590511322\n",
            "Epoch [401/500], Loss: 0.5537488460540771\n",
            "Epoch [402/500], Loss: 0.6353299021720886\n",
            "Epoch [403/500], Loss: 0.5979756116867065\n",
            "Epoch [404/500], Loss: 0.5721551179885864\n",
            "Epoch [405/500], Loss: 0.5812206268310547\n",
            "Epoch [406/500], Loss: 0.6199913620948792\n",
            "Epoch [407/500], Loss: 0.710759699344635\n",
            "Epoch [408/500], Loss: 0.600081741809845\n",
            "Epoch [409/500], Loss: 0.5460601449012756\n",
            "Epoch [410/500], Loss: 0.5681412220001221\n",
            "Epoch [411/500], Loss: 0.6682915091514587\n",
            "Epoch [412/500], Loss: 0.6259123682975769\n",
            "Epoch [413/500], Loss: 0.5523703694343567\n",
            "Epoch [414/500], Loss: 0.5306478142738342\n",
            "Epoch [415/500], Loss: 0.670460045337677\n",
            "Epoch [416/500], Loss: 0.6812290549278259\n",
            "Epoch [417/500], Loss: 0.6080900430679321\n",
            "Epoch [418/500], Loss: 0.5529873967170715\n",
            "Epoch [419/500], Loss: 0.6536658406257629\n",
            "Epoch [420/500], Loss: 0.6072787642478943\n",
            "Epoch [421/500], Loss: 0.6653531193733215\n",
            "Epoch [422/500], Loss: 0.5985180139541626\n",
            "Epoch [423/500], Loss: 0.5996105074882507\n",
            "Epoch [424/500], Loss: 0.6512449979782104\n",
            "Epoch [425/500], Loss: 0.5938648581504822\n",
            "Epoch [426/500], Loss: 0.5968350172042847\n",
            "Epoch [427/500], Loss: 0.6500835418701172\n",
            "Epoch [428/500], Loss: 0.5761941075325012\n",
            "Epoch [429/500], Loss: 0.5673946738243103\n",
            "Epoch [430/500], Loss: 0.6659106016159058\n",
            "Epoch [431/500], Loss: 0.5641239285469055\n",
            "Epoch [432/500], Loss: 0.6839584112167358\n",
            "Epoch [433/500], Loss: 0.6325299143791199\n",
            "Epoch [434/500], Loss: 0.624655544757843\n",
            "Epoch [435/500], Loss: 0.6369003653526306\n",
            "Epoch [436/500], Loss: 0.6441369652748108\n",
            "Epoch [437/500], Loss: 0.5757566690444946\n",
            "Epoch [438/500], Loss: 0.5474015474319458\n",
            "Epoch [439/500], Loss: 0.5926730632781982\n",
            "Epoch [440/500], Loss: 0.5983460545539856\n",
            "Epoch [441/500], Loss: 0.5229740738868713\n",
            "Epoch [442/500], Loss: 0.582865297794342\n",
            "Epoch [443/500], Loss: 0.5427613854408264\n",
            "Epoch [444/500], Loss: 0.5837225914001465\n",
            "Epoch [445/500], Loss: 0.5738692879676819\n",
            "Epoch [446/500], Loss: 0.6619136929512024\n",
            "Epoch [447/500], Loss: 0.6366722583770752\n",
            "Epoch [448/500], Loss: 0.5652878284454346\n",
            "Epoch [449/500], Loss: 0.5497719049453735\n",
            "Epoch [450/500], Loss: 0.5378633141517639\n",
            "Epoch [451/500], Loss: 0.4902045726776123\n",
            "Epoch [452/500], Loss: 0.6183560490608215\n",
            "Epoch [453/500], Loss: 0.46025165915489197\n",
            "Epoch [454/500], Loss: 0.657275378704071\n",
            "Epoch [455/500], Loss: 0.611810028553009\n",
            "Epoch [456/500], Loss: 0.5173643827438354\n",
            "Epoch [457/500], Loss: 0.6293707489967346\n",
            "Epoch [458/500], Loss: 0.5190612077713013\n",
            "Epoch [459/500], Loss: 0.570753276348114\n",
            "Epoch [460/500], Loss: 0.6872456669807434\n",
            "Epoch [461/500], Loss: 0.5086298584938049\n",
            "Epoch [462/500], Loss: 0.5770038962364197\n",
            "Epoch [463/500], Loss: 0.6201967597007751\n",
            "Epoch [464/500], Loss: 0.6161743998527527\n",
            "Epoch [465/500], Loss: 0.6332609057426453\n",
            "Epoch [466/500], Loss: 0.5601511597633362\n",
            "Epoch [467/500], Loss: 0.6078744530677795\n",
            "Epoch [468/500], Loss: 0.5634905099868774\n",
            "Epoch [469/500], Loss: 0.5847561359405518\n",
            "Epoch [470/500], Loss: 0.6611071825027466\n",
            "Epoch [471/500], Loss: 0.569031834602356\n",
            "Epoch [472/500], Loss: 0.6281759142875671\n",
            "Epoch [473/500], Loss: 0.535999596118927\n",
            "Epoch [474/500], Loss: 0.6528806090354919\n",
            "Epoch [475/500], Loss: 0.552871823310852\n",
            "Epoch [476/500], Loss: 0.6685847640037537\n",
            "Epoch [477/500], Loss: 0.6263470649719238\n",
            "Epoch [478/500], Loss: 0.5054710507392883\n",
            "Epoch [479/500], Loss: 0.658656656742096\n",
            "Epoch [480/500], Loss: 0.6145817637443542\n",
            "Epoch [481/500], Loss: 0.5650697946548462\n",
            "Epoch [482/500], Loss: 0.6100549101829529\n",
            "Epoch [483/500], Loss: 0.5857332348823547\n",
            "Epoch [484/500], Loss: 0.5083509683609009\n",
            "Epoch [485/500], Loss: 0.579193115234375\n",
            "Epoch [486/500], Loss: 0.5686294436454773\n",
            "Epoch [487/500], Loss: 0.589104413986206\n",
            "Epoch [488/500], Loss: 0.5574889183044434\n",
            "Epoch [489/500], Loss: 0.6746444702148438\n",
            "Epoch [490/500], Loss: 0.4849826395511627\n",
            "Epoch [491/500], Loss: 0.6817752718925476\n",
            "Epoch [492/500], Loss: 0.6621711254119873\n",
            "Epoch [493/500], Loss: 0.5323209166526794\n",
            "Epoch [494/500], Loss: 0.5183178782463074\n",
            "Epoch [495/500], Loss: 0.5919983983039856\n",
            "Epoch [496/500], Loss: 0.5470101833343506\n",
            "Epoch [497/500], Loss: 0.63323974609375\n",
            "Epoch [498/500], Loss: 0.5355827212333679\n",
            "Epoch [499/500], Loss: 0.5725862383842468\n",
            "Epoch [500/500], Loss: 0.5658916234970093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_t)\n",
        "    y_pred = (y_pred >= 0.5).float()\n",
        "    accuracy = (y_pred == y_test_t.view(-1, 1)).float().mean()\n",
        "    print(f'Accuracy on test set: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PLyxv-9IyQP",
        "outputId": "7f6a52e5-01a8-4eb0-c6f7-0b2fcda6e1a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.6447368264198303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our single layer perceptron has a test accuracy of 76.97%\n",
        "\n"
      ],
      "metadata": {
        "id": "9stzVWFg5JJ1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EwpVd5DcYxiMsSCJ73h2NmTJqBaDFhXs",
      "authorship_tag": "ABX9TyNW+lzsV1WNcGnD8ihWv61r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}